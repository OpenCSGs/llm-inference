apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  labels:
    controller-tools.k8s.io: "1.0"
  name: opencsg
  namespace: ray
spec:
  rayVersion: '2.8.0' # should match the Ray version in the image of the containers
  # Ray head pod template
  headGroupSpec:
    # The `rayStartParams` are used to configure the `ray start` command.
    # See https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayStartParams.md for the default settings of `rayStartParams` in KubeRay.
    # See https://docs.ray.io/en/latest/cluster/cli.html#ray-start for all available options in `rayStartParams`.
    rayStartParams:
      resources: '"{\"accelerator_type_cpu\": 2}"'
      dashboard-host: '0.0.0.0'
      dashboard-port: '8265'
      num-gpus: "0"
      num-cpus: "0"
    #pod template
    template:
      spec:
        containers:
        - name: ray-head
          image: sean/llmray:0.0.2-036f6b1d3918
          resources:
            limits:
              cpu: 2
              memory: 4Gi
              nvidia.com/gpu: 0
            requests:
              cpu: 2
              memory: 4Gi
              nvidia.com/gpu: 0
          ports:
          - containerPort: 6379
            name: gcs-server
          - containerPort: 8265 # Ray dashboard
            name: dashboard
          - containerPort: 10001
            name: client
          - containerPort: 8000
            name: serveport
          volumeMounts:
          - name: local-model
            mountPath: /tmp/hub
        volumes:
        - name: local-model
          hostPath:
            path: /data/minio/huggingface/hub
  workerGroupSpecs:
  # the pod replicas in this group typed worker
  - replicas: 1
    minReplicas: 0
    maxReplicas: 1
    # logical group name, for this called small-group, also can be functional
    groupName: gpu-group
    rayStartParams:
      resources: '"{\"accelerator_type_cpu\": 4, \"accelerator_type_gpu\": 1}"'
    #pod template
    template:
      spec:
        containers:
        - name: llm
          image: sean/llmray:0.0.2-036f6b1d3918
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
          resources:
            limits:
              cpu: 8
              memory: 32Gi
              nvidia.com/gpu: 1
            requests:
              cpu: 8
              memory: 32Gi
              nvidia.com/gpu: 1
          volumeMounts:
          - name: local-model
            mountPath: /tmp/hub
        volumes:
        - name: local-model
          hostPath:
            path: /data/minio/huggingface/hub
        # Please add the following taints to the GPU node.
        tolerations:
          - key: "ray.io/node-type"
            operator: "Equal"
            value: "worker"
            effect: "NoSchedule"
